to get the VM size of the run 

sacct -j jobid --format='MaxVMSize'


#!/bin/bash
##Not all of these options are required
#SBATCH --partition=compute             # Select queue to run your job (always compute)
#SBATCH --job-name=sav_360                 # Job name
#SBATCH --ntasks=32                     # Number of MPI ranks
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=32

###SBATCH --mail-type=ALL                 # Mail events (NONE, BEGIN, END, FAIL, ALL)
###SBATCH --mail-user=jcwarner@usgs.gov   # Where to send mail  
###SBATCH --ntasks-per-socket=6           # How many tasks on each CPU or socket
###SBATCH --cpus-per-task=1               # Number of cores per MPI rank  - jcw for OpenMP?
###SBATCH --distribution=cyclic:cyclic    # Distribute tasks cyclically on nodes and sockets

##SBATCH --mem-per-cpu=21gb             # Memory per processor
#SBATCH --time=00:10:00                 # Time limit hrs:min:sec
#SBATCH --output=mpi_test_%j.log        # Standard output and error log

pwd; hostname; date

echo "Running COAWST on $SLURM_JOB_NUM_NODES nodes with $SLURM_NTASKS tasks, each with $SLURM_CPUS_PER_TASK cores."

module load intel/2018 openmpi/intel/3.0.1 netcdf/intel/4.6.1

mpirun -np 32 coawstM  /vortexfs1/scratch/tkalra/sav_test_allcouple/ocean_veg_test_sav.in
